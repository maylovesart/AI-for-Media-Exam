{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOM7xGUTBqmTdewXYn6uulZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maylovesart/AI-for-Media-Exam/blob/main/UK_Black_Icons_GANs_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG9h4UZDTzGS",
        "outputId": "2d52d49c-c80b-47dd-9980-5fdc71a3bd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Loaded 12 content images and 20 style images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 500 epochs...\n",
            "Epoch 10/500, Time: 0.30 sec\n",
            "Generator Loss: 3.2190, Discriminator Loss: 0.4077\n",
            "Epoch 20/500, Time: 0.31 sec\n",
            "Generator Loss: 3.1055, Discriminator Loss: 0.5042\n",
            "Epoch 30/500, Time: 0.33 sec\n",
            "Generator Loss: 3.3736, Discriminator Loss: 0.3832\n",
            "Epoch 40/500, Time: 0.33 sec\n",
            "Generator Loss: 3.8142, Discriminator Loss: 0.3739\n",
            "Epoch 50/500, Time: 0.34 sec\n",
            "Generator Loss: 3.7973, Discriminator Loss: 0.3712\n",
            "Epoch 60/500, Time: 0.33 sec\n",
            "Generator Loss: 3.9994, Discriminator Loss: 0.4116\n",
            "Epoch 70/500, Time: 0.32 sec\n",
            "Generator Loss: 2.8246, Discriminator Loss: 0.4157\n",
            "Epoch 80/500, Time: 0.32 sec\n",
            "Generator Loss: 2.4196, Discriminator Loss: 0.4561\n",
            "Epoch 90/500, Time: 0.30 sec\n",
            "Generator Loss: 2.8741, Discriminator Loss: 0.4886\n",
            "Epoch 100/500, Time: 0.29 sec\n",
            "Generator Loss: 2.6603, Discriminator Loss: 0.4834\n",
            "Epoch 110/500, Time: 0.29 sec\n",
            "Generator Loss: 0.6460, Discriminator Loss: 1.3016\n",
            "Epoch 120/500, Time: 0.29 sec\n",
            "Generator Loss: 2.5519, Discriminator Loss: 0.4825\n",
            "Epoch 130/500, Time: 0.29 sec\n",
            "Generator Loss: 3.0704, Discriminator Loss: 0.4840\n",
            "Epoch 140/500, Time: 0.28 sec\n",
            "Generator Loss: 3.3748, Discriminator Loss: 0.4380\n",
            "Epoch 150/500, Time: 0.28 sec\n",
            "Generator Loss: 2.8591, Discriminator Loss: 0.4344\n",
            "Epoch 160/500, Time: 0.29 sec\n",
            "Generator Loss: 3.6100, Discriminator Loss: 0.4314\n",
            "Epoch 170/500, Time: 0.28 sec\n",
            "Generator Loss: 3.4932, Discriminator Loss: 0.4011\n",
            "Epoch 180/500, Time: 0.29 sec\n",
            "Generator Loss: 2.3327, Discriminator Loss: 0.5937\n",
            "Epoch 190/500, Time: 0.29 sec\n",
            "Generator Loss: 3.0301, Discriminator Loss: 0.4407\n",
            "Epoch 200/500, Time: 0.29 sec\n",
            "Generator Loss: 3.5230, Discriminator Loss: 0.4084\n",
            "Epoch 210/500, Time: 0.29 sec\n",
            "Generator Loss: 3.3083, Discriminator Loss: 0.4176\n",
            "Epoch 220/500, Time: 0.29 sec\n",
            "Generator Loss: 2.4260, Discriminator Loss: 0.5460\n",
            "Epoch 230/500, Time: 0.29 sec\n",
            "Generator Loss: 2.2838, Discriminator Loss: 0.5209\n",
            "Epoch 240/500, Time: 0.29 sec\n",
            "Generator Loss: 3.4151, Discriminator Loss: 0.5957\n",
            "Epoch 250/500, Time: 0.29 sec\n",
            "Generator Loss: 3.4900, Discriminator Loss: 0.5906\n",
            "Epoch 260/500, Time: 0.29 sec\n",
            "Generator Loss: 1.9323, Discriminator Loss: 0.6458\n",
            "Epoch 270/500, Time: 0.29 sec\n",
            "Generator Loss: 3.0127, Discriminator Loss: 0.4818\n",
            "Epoch 280/500, Time: 0.29 sec\n",
            "Generator Loss: 1.7740, Discriminator Loss: 0.6341\n",
            "Epoch 290/500, Time: 0.30 sec\n",
            "Generator Loss: 2.7082, Discriminator Loss: 0.4804\n",
            "Epoch 300/500, Time: 0.30 sec\n",
            "Generator Loss: 2.7386, Discriminator Loss: 0.6048\n",
            "Epoch 310/500, Time: 0.30 sec\n",
            "Generator Loss: 3.2688, Discriminator Loss: 0.6376\n",
            "Epoch 320/500, Time: 0.30 sec\n",
            "Generator Loss: 1.7729, Discriminator Loss: 0.6981\n",
            "Epoch 330/500, Time: 0.30 sec\n",
            "Generator Loss: 0.4112, Discriminator Loss: 1.7132\n",
            "Epoch 340/500, Time: 0.29 sec\n",
            "Generator Loss: 2.0997, Discriminator Loss: 0.5886\n",
            "Epoch 350/500, Time: 0.29 sec\n",
            "Generator Loss: 2.4627, Discriminator Loss: 0.6821\n",
            "Epoch 360/500, Time: 0.29 sec\n",
            "Generator Loss: 1.7968, Discriminator Loss: 0.6651\n",
            "Epoch 370/500, Time: 0.29 sec\n",
            "Generator Loss: 1.6922, Discriminator Loss: 0.6862\n",
            "Epoch 380/500, Time: 0.29 sec\n",
            "Generator Loss: 3.2190, Discriminator Loss: 0.8539\n",
            "Epoch 390/500, Time: 0.29 sec\n",
            "Generator Loss: 1.4537, Discriminator Loss: 0.8267\n",
            "Epoch 400/500, Time: 0.29 sec\n",
            "Generator Loss: 1.4725, Discriminator Loss: 0.8114\n",
            "Epoch 410/500, Time: 0.29 sec\n",
            "Generator Loss: 2.0844, Discriminator Loss: 0.7528\n",
            "Epoch 420/500, Time: 0.29 sec\n",
            "Generator Loss: 2.3176, Discriminator Loss: 0.7904\n",
            "Epoch 430/500, Time: 0.29 sec\n",
            "Generator Loss: 1.5926, Discriminator Loss: 0.8138\n",
            "Epoch 440/500, Time: 0.29 sec\n",
            "Generator Loss: 1.4179, Discriminator Loss: 0.7758\n",
            "Epoch 450/500, Time: 0.29 sec\n",
            "Generator Loss: 2.0457, Discriminator Loss: 0.7759\n",
            "Epoch 460/500, Time: 0.29 sec\n",
            "Generator Loss: 1.6659, Discriminator Loss: 0.8764\n",
            "Epoch 470/500, Time: 0.29 sec\n",
            "Generator Loss: 1.1505, Discriminator Loss: 0.8603\n",
            "Epoch 480/500, Time: 0.29 sec\n",
            "Generator Loss: 1.3526, Discriminator Loss: 0.8373\n",
            "Epoch 490/500, Time: 0.29 sec\n",
            "Generator Loss: 1.3945, Discriminator Loss: 0.7997\n",
            "Epoch 500/500, Time: 0.28 sec\n",
            "Generator Loss: 1.2975, Discriminator Loss: 0.7901\n",
            "Training complete.\n",
            "\n",
            "Ethical Considerations:\n",
            "This project involves generating images based on real individuals.\n",
            "It's important to consider the ethical implications of creating and using such images.\n",
            "The generated images should not be used for misrepresentation or without proper context.\n",
            "\n",
            "LLM Disclaimer:\n",
            "Large Language Models were used for code structuring and debugging assistance.\n",
            "All implementation decisions and parameter tuning were made by the human developer.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set TensorFlow to use GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# Load and Preprocess Images\n",
        "TARGET_SIZE = (256, 256)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.resize(img, TARGET_SIZE)\n",
        "    img = img / 127.5 - 1  # Normalize to [-1, 1]\n",
        "    return img\n",
        "\n",
        "def load_and_preprocess_images(directory):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img = preprocess_image(img_path)\n",
        "            images.append(img)\n",
        "    return tf.stack(images)\n",
        "\n",
        "# Load images from the specified directories\n",
        "content_images = load_and_preprocess_images(\"/content/Diane Abbott\")\n",
        "style_images = load_and_preprocess_images(\"/content/Richard Stone\")\n",
        "\n",
        "print(f\"Loaded {len(content_images)} content images and {len(style_images)} style images.\")\n",
        "\n",
        "# Data Augmentation\n",
        "def augment_image(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    return image\n",
        "\n",
        "# GAN Model Definition\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(16 * 16 * 256, use_bias=False, input_shape=(100,)),\n",
        "        tf.keras.layers.Reshape((16, 16, 256)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Conv2DTranspose(128, 5, strides=2, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Conv2DTranspose(64, 5, strides=2, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Conv2DTranspose(32, 5, strides=2, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Conv2DTranspose(3, 5, strides=2, padding='same', activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, 5, strides=2, padding='same', input_shape=[256, 256, 3]),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, 5, strides=2, padding='same'),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Loss Functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) * 0.9, real_output)  # Label smoothing\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Optimizers with learning rate scheduling\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-4,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96\n",
        ")\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
        "\n",
        "# Training Step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    noise = tf.random.normal([batch_size, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# Generate and Save Images\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :, :] * 0.5 + 0.5)  # Denormalize\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f'/content/generated_image_epoch_{epoch}.png')\n",
        "    plt.close()\n",
        "\n",
        "# Training Loop\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch)\n",
        "\n",
        "        # Print updates every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Time: {time.time()-start:.2f} sec\")\n",
        "            print(f\"Generator Loss: {gen_loss:.4f}, Discriminator Loss: {disc_loss:.4f}\")\n",
        "\n",
        "        # Generate and save images every 20 epochs\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "    # Generate a final set of images\n",
        "    generate_and_save_images(generator, epochs, seed)\n",
        "\n",
        "# Prepare the dataset\n",
        "BATCH_SIZE = 32  # Increased batch size\n",
        "EPOCHS = 500  # Increased number of epochs\n",
        "\n",
        "# Combine content and style images\n",
        "combined_images = tf.concat([content_images, style_images], axis=0)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(combined_images)\n",
        "dataset = dataset.map(augment_image)  # Apply data augmentation\n",
        "dataset = dataset.shuffle(1000).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Initialize models\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "# Create a seed for image generation\n",
        "seed = tf.random.normal([16, 100])\n",
        "\n",
        "# Start training\n",
        "print(\"Starting training for 500 epochs...\")\n",
        "train(dataset, EPOCHS)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Ethical considerations and LLM disclaimer\n",
        "print(\"\\nEthical Considerations:\")\n",
        "print(\"This project involves generating images based on real individuals.\")\n",
        "print(\"It's important to consider the ethical implications of creating and using such images.\")\n",
        "print(\"The generated images should not be used for misrepresentation or without proper context.\")\n",
        "\n",
        "print(\"\\nLLM Disclaimer:\")\n",
        "print(\"Large Language Models were used for code structuring and debugging assistance.\")\n",
        "print(\"All implementation decisions and parameter tuning were made by the human developer.\")"
      ]
    }
  ]
}